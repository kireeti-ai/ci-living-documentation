import subprocess
import datetime
import json
import os
import sys


SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
REPORT_FILE = os.path.join(SCRIPT_DIR, "testing_report.md")
JSON_REPORT = "report.json"


def run_pytest():
    """Run pytest with coverage and JSON reporting"""
    result = subprocess.run(
        [
            sys.executable,
            "-m",
            "pytest",
            "--cov=.",
            "--cov-report=term",
            "--cov-report=json:coverage.json",
            "--json-report",
            f"--json-report-file={JSON_REPORT}",
        ],
        capture_output=True,
        text=True,
    )

    return result.returncode


def load_json(path):
    if not os.path.exists(path):
        return {}
    with open(path, "r") as f:
        return json.load(f)


def get_git_commit():
    try:
        commit = subprocess.check_output(
            ["git", "rev-parse", "--short", "HEAD"],
            text=True
        ).strip()
        return commit
    except Exception:
        return "Unknown"


def get_ci_build_id():
    return (
        os.getenv("GITHUB_RUN_ID")
        or os.getenv("CI_PIPELINE_ID")
        or os.getenv("BUILD_BUILDID")
        or "Local-Build"
    )


def extract_failed_tests(results):
    failed_tests = []

    tests = results.get("tests", [])
    for test in tests:
        if test.get("outcome") == "failed":
            failed_tests.append(test.get("nodeid"))

    return failed_tests


def get_coverage_percent():
    coverage_data = load_json("coverage.json")
    totals = coverage_data.get("totals", {})
    return round(totals.get("percent_covered", 0), 2)


def generate_markdown(results, status):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    summary = results.get("summary", {})
    total = summary.get("total", 0)
    passed = summary.get("passed", 0)
    failed = summary.get("failed", 0)

    failed_tests = extract_failed_tests(results)
    coverage = get_coverage_percent()
    commit_hash = get_git_commit()
    build_id = get_ci_build_id()

    overall_status = "Pass" if status == 0 else "Fail"

    failed_section = (
        "\n".join([f"- {t}" for t in failed_tests])
        if failed_tests
        else "No failed tests."
    )

    content = f"""# Testing

## 1. Test Plan

### Introduction/Purpose
Validate EPIC-2 documentation intelligence pipeline including validation, snapshot generation, documentation artifacts, and backend contract integrity.

### Scope
In-Scope:
- Impact report validation
- Snapshot generation
- README, API, ADR, Diagram generation
- Backend API contract
- Schema validation

Out-of-Scope:
- Real LLM API execution
- Production object storage
- Performance benchmarking

### Testing Approach
- Automated unit testing using pytest
- Coverage measurement via pytest-cov
- JSON-based reporting
- Mocked subprocess and external dependencies

### Test Environment
- Python 3.x
- pytest
- Local or CI execution

### Entry & Exit Criteria
Entry:
- Dependencies installed
Exit:
- All tests pass
- Coverage meets threshold

---

## 2. Test Case Summary

Total Tests: {total}  
Passed: {passed}  
Failed: {failed}  
Coverage: {coverage}%  

---

## 3. Defect/Bug Report

### Failed Test Cases
{failed_section}

---

## 4. Test Execution Report

Project Name: CI Living Documentation â€“ EPIC-2  
Execution Date: {now}  
CI Build ID: {build_id}  
Commit Hash: {commit_hash}

Command Executed:
```bash
pytest --cov=. --json-report
```

## 5. Conclusion
Status: **{overall_status}**

This report was automatically generated by the CI pipeline.
"""
    return content


def main():
    print("Running tests...")
    status = run_pytest()
    
    print("Loading results...")
    results = load_json(JSON_REPORT)
    
    print("Generating report...")
    report_content = generate_markdown(results, status)
    
    with open(REPORT_FILE, "w", encoding="utf-8") as f:
        f.write(report_content)
        
    print(f"Report generated: {REPORT_FILE}")

if __name__ == "__main__":
    main()
