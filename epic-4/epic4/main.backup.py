import argparse
import os
import sys
import glob
from epic4.config import config
from epic4.utils import logger
from epic4.summary import generate_summary
from epic4.github_client import GitHubClient
from epic4.storage_client import StorageClient

def main():
    parser = argparse.ArgumentParser(description="Epic-4 CI Automation")
    parser.add_argument("--impact", default=config.IMPACT_REPORT_PATH, help="Path to impact report")
    parser.add_argument("--drift", default=config.DRIFT_REPORT_PATH, help="Path to drift report")
    parser.add_argument("--docs", default=config.DOCS_DIR, help="Path to docs directory")
    parser.add_argument("--commit", default=config.COMMIT_SHA, help="Commit SHA")
    parser.add_argument("--mode", default=config.EXECUTION_MODE, help="Execution mode: FULL_MODE or SUMMARY_ONLY_MODE")

    args = parser.parse_args()

    # 1. Validation & Input Loading
    requested_mode = (args.mode or "FULL_MODE").strip().upper()
    if requested_mode not in ["FULL_MODE", "SUMMARY_ONLY_MODE"]:
        logger.warning(f"Unknown mode '{args.mode}', defaulting to FULL_MODE")
        requested_mode = "FULL_MODE"

    git_available = bool(config.REPO_OWNER and config.REPO_NAME and config.GITHUB_TOKEN)
    effective_mode = requested_mode

    if requested_mode == "FULL_MODE" and not git_available:
        logger.warning("Git credentials missing; switching to SUMMARY_ONLY_MODE")
        effective_mode = "SUMMARY_ONLY_MODE"

    if effective_mode == "FULL_MODE":
        try:
            config.validate(require_git=True)
        except ValueError as e:
            logger.error(f"Configuration error: {e}")
            logger.warning("Falling back to SUMMARY_ONLY_MODE")
            effective_mode = "SUMMARY_ONLY_MODE"

    # Load doc_snapshot.json to get dynamic bucket path and project_id
    docs_bucket_path = config.DOCS_BUCKET_PATH  # Prefer explicit env config
    project_id = None
    summaries_dir = config.SUMMARIES_DIR  # Default fallback
    
    if os.path.exists(config.DOC_SNAPSHOT_PATH):
        try:
            import json
            with open(config.DOC_SNAPSHOT_PATH, 'r') as f:
                snapshot = json.load(f)
                # Extract project_id
                project_id = snapshot.get("project_id")
                if project_id:
                    # Construct path: project_id/{commit_sha}/docs/summaries
                    summaries_dir = os.path.join(project_id, args.commit, "docs", "summaries")
                    logger.info(f"Loaded project_id from snapshot: {project_id}")
                    logger.info(f"Summaries will be stored in: {summaries_dir}")
                else:
                    logger.warning("project_id not found in doc_snapshot.json, using default summaries directory")
                
                # Extract bucket path
                if not docs_bucket_path:
                    docs_bucket_path = snapshot.get("docs_bucket_path", docs_bucket_path)
                    logger.info(f"Loaded bucket path from snapshot: {docs_bucket_path}")
                else:
                    logger.info("Using DOCS_BUCKET_PATH from environment; ignoring snapshot value")
        except Exception as e:
            logger.warning(f"Failed to load doc_snapshot.json: {e}")
    else:
        logger.warning(f"doc_snapshot.json not found at {config.DOC_SNAPSHOT_PATH}")

    logger.info(f"Starting Epic-4 execution for commit {args.commit} in mode {effective_mode}")

    storage_client = StorageClient()

    # 2. Download documentation artifacts from cloud storage if configured
    if effective_mode == "FULL_MODE" and docs_bucket_path:
        logger.info(f"Downloading docs from cloud storage: {docs_bucket_path}")
        success = storage_client.download_artifacts(docs_bucket_path, args.docs)
        if not success:
            logger.warning("Failed to download from cloud storage, continuing with local files")
    elif effective_mode == "FULL_MODE":
        logger.info("No cloud storage path configured, using local docs")

    # 3. Generate Summary with fault tolerance
    summary_md_path = ""
    summary_json_path = ""
    
    try:
        summary_md_path, summary_json_path = generate_summary(args.impact, args.drift, args.commit, summaries_dir)
        with open(summary_md_path, 'r') as f:
            summary_content = f.read()
    except Exception as e:
        logger.error(f"Failed to generate summary: {e}")
        # Create error summary for partial artifact preservation
        summary_md_path = os.path.join(summaries_dir, "summary.md")
        summary_json_path = os.path.join(summaries_dir, "summary.json")
        os.makedirs(summaries_dir, exist_ok=True)
        
        summary_content = f"""# Change Summary - Generation Failed

**Commit SHA:** `{args.commit}`
**Status:** ERROR

## Error
Summary generation encountered an error:
```
{str(e)}
```

This is a degraded artifact. Please check the impact and drift reports manually.

---
*Generated by Epic-4 Automation*
"""
        with open(summary_md_path, 'w') as f:
            f.write(summary_content)
            
        with open(summary_json_path, 'w') as f:
            import json
            json.dump({"error": str(e), "status": "ERROR", "commit_sha": args.commit}, f)
            
        logger.info(f"Created error summary at {summary_md_path}")

    pr_number = None
    pr_url = ""
    pr_metadata_path = ""

    if effective_mode == "FULL_MODE":
        # 4. Collect Files for Git
        files_to_commit = []

        # Docs
        if os.path.isdir(args.docs):
            for root, dirs, files in os.walk(args.docs):
                for file in files:
                    files_to_commit.append(os.path.join(root, file))

        # Summary
        files_to_commit.append(summary_md_path)

        logger.info(f"Files to commit: {len(files_to_commit)}")

        # 5. Git Operations & PR
        gh = GitHubClient(config.REPO_OWNER, config.REPO_NAME, config.GITHUB_TOKEN)

        branch_name = f"docs/update-{args.commit}"

        try:
            # Push artifacts
            gh.checkout_and_push_files(
                branch_name=branch_name,
                files_to_commit=files_to_commit,
                message=f"Auto-generated docs and summary for {args.commit}"
            )

            # Create/Update PR
            pr_number_str = gh.ensure_pr(
                head_branch=branch_name,
                base_branch=config.TARGET_BRANCH,
                title="Automated Documentation & Summary Update",
                body=summary_content,
                labels=["auto-generated-docs"]
            )
            pr_number = int(pr_number_str)
            pr_url = f"https://github.com/{config.REPO_OWNER}/{config.REPO_NAME}/pull/{pr_number}"

            logger.info(f"Successfully processed PR #{pr_number}")

        except Exception as e:
            logger.error(f"Automation failed: {e}")
            # If git ops fail, we might still want to upload what we have, but continue gracefully.
        finally:
            gh.cleanup()

        # 6. Generate PR Metadata
        pr_metadata_path = os.path.join(config.ARTIFACTS_DIR, "pr_metadata.json")
        try:
            import json
            with open(pr_metadata_path, 'w') as f:
                json.dump({
                    "pr_number": pr_number,
                    "pr_url": pr_url,
                    "branch": branch_name,
                    "commit_sha": args.commit
                }, f, indent=2)
        except Exception as e:
            logger.error(f"Failed to generate pr_metadata.json: {e}")

        # 7. Upload Artifacts to Cloud Storage (Epic-5 requirement)
        if docs_bucket_path:
            logger.info(f"Uploading CI artifacts to {docs_bucket_path}")
            storage_client.upload_file(summary_md_path, docs_bucket_path)
            storage_client.upload_file(summary_json_path, docs_bucket_path)
            if pr_metadata_path and os.path.exists(pr_metadata_path):
                storage_client.upload_file(pr_metadata_path, docs_bucket_path)
        else:
            logger.warning("No bucket path available for artifact upload")
    else:
        # SUMMARY_ONLY_MODE: optional artifact upload
        if docs_bucket_path:
            logger.info(f"Uploading summary artifacts to {docs_bucket_path}")
            storage_client.upload_file(summary_md_path, docs_bucket_path)
            storage_client.upload_file(summary_json_path, docs_bucket_path)
        else:
            logger.info("No bucket path available for summary upload")

    # 8. Emit response payload
    response = {
        "status": "success",
        "mode": effective_mode
    }
    if effective_mode == "FULL_MODE":
        response.update({
            "pr_url": pr_url,
            "artifacts": [summary_md_path, summary_json_path] + ([pr_metadata_path] if pr_metadata_path else [])
        })
    else:
        response.update({
            "summary_generated": True
        })

    try:
        import json
        print(json.dumps(response))
    except Exception:
        print(response)

if __name__ == "__main__":
    main()
